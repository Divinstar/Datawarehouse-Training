{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VVkLAzhkneg9"
      },
      "outputs": [],
      "source": [
        "# Remove old spark folder if exists (just in case)\n",
        "!rm -rf /content/spark-3.4.1-bin-hadoop3\n",
        "!rm -rf /content/spark-3.3.0-bin-hadoop3\n",
        "\n",
        "# Install Java 8 (required by Spark)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Spark 3.3.0 (stable and tested on Colab)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.0-bin-hadoop3.tgz\n",
        "\n",
        "# Install findspark to locate Spark from Python\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\"\n"
      ],
      "metadata": {
        "id": "Az_fV9ttn19a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"WarehouseStockAnalysis\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "sWZIYR7Pn5Cz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate total stock by warehouse only\n",
        "warehouse_agg = agg_df.groupBy(\"warehouse_id\").agg(_sum(\"total_stock\").alias(\"warehouse_stock\"))\n",
        "\n",
        "# Flag warehouse status\n",
        "warehouse_status = warehouse_agg.withColumn(\n",
        "    \"warehouse_stock_status\",\n",
        "    when(col(\"warehouse_stock\") < 50, \"UNDERSTOCKED\")\n",
        "    .when(col(\"warehouse_stock\") > 500, \"OVERSTOCKED\")\n",
        "    .otherwise(\"NORMAL\")\n",
        ")\n",
        "\n",
        "warehouse_status.show()\n",
        "\n",
        "# Save output CSV\n",
        "warehouse_status.write.csv(\"warehouse_stock_status_output\", header=True, mode=\"overwrite\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK5MOHBGoFCl",
        "outputId": "39ed5667-08a1-483c-c9fb-7f1c52dc2323"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+----------------------+\n",
            "|warehouse_id|warehouse_stock|warehouse_stock_status|\n",
            "+------------+---------------+----------------------+\n",
            "|         108|             95|                NORMAL|\n",
            "|         101|            240|                NORMAL|\n",
            "|         103|              2|          UNDERSTOCKED|\n",
            "|         107|              1|          UNDERSTOCKED|\n",
            "|         102|             10|          UNDERSTOCKED|\n",
            "|         105|              1|          UNDERSTOCKED|\n",
            "|         106|            200|                NORMAL|\n",
            "|         104|            200|                NORMAL|\n",
            "+------------+---------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}