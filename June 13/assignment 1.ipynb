{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oiEqKkUVp0EZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "!rm -rf /content/spark-3.4.1-bin-hadoop3\n",
        "!rm -rf /content/spark-3.3.0-bin-hadoop3\n",
        "\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.0-bin-hadoop3.tgz\n",
        "\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, avg, desc, sum as _sum\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Dataset assignemnt\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "f4jQ5sUlp4Kb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"customers.csv\", \"w\") as f:\n",
        "    f.write(\"CustomerID,Name,City,Age\\n\")\n",
        "    f.write(\"101,Aditi,Mumbai,28\\n\")\n",
        "    f.write(\"102,Rohan,Delhi,35\\n\")\n",
        "    f.write(\"103,Meena,Bangalore,41\\n\")\n",
        "    f.write(\"104,Kabir,Hyderabad,30\\n\")\n",
        "    f.write(\"105,Zoya,Chennai,25\\n\")\n",
        "\n",
        "with open(\"orders.csv\", \"w\") as f:\n",
        "    f.write(\"OrderID,CustomerID,Product,Quantity,Price,OrderDate\\n\")\n",
        "    f.write(\"1001,101,Laptop,1,70000,2024-01-05\\n\")\n",
        "    f.write(\"1002,102,Mobile,2,25000,2024-02-10\\n\")\n",
        "    f.write(\"1003,103,Desk,1,10000,2024-03-15\\n\")\n",
        "    f.write(\"1004,101,Mouse,3,1000,2024-04-01\\n\")\n",
        "    f.write(\"1005,104,Monitor,1,12000,2024-04-25\\n\")\n"
      ],
      "metadata": {
        "id": "ZemWnqu7qRPT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_df = spark.read.csv(\"customers.csv\", header=True, inferSchema=True)\n",
        "orders_df = spark.read.csv(\"orders.csv\", header=True, inferSchema=True)\n",
        "\n",
        "customers_df.printSchema()\n",
        "orders_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cszTF70LqbP8",
        "outputId": "3e48e5cd-2cc4-4c58-cadd-9e2722960d89"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: integer (nullable = true)\n",
            " |-- OrderDate: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Quantity\") * col(\"Price\"))\n",
        "\n",
        "joined_df = orders_df.join(customers_df, on=\"CustomerID\", how=\"inner\")\n",
        "\n",
        "filtered_orders = joined_df.filter(col(\"TotalAmount\") > 20000)\n",
        "\n",
        "multi_orders = joined_df.groupBy(\"CustomerID\").agg(count(\"OrderID\").alias(\"OrderCount\")) \\\n",
        "    .filter(col(\"OrderCount\") > 1)\n",
        "\n",
        "avg_order_by_city = joined_df.groupBy(\"City\").agg(avg(\"TotalAmount\").alias(\"AvgOrderValue\"))\n",
        "\n",
        "sorted_orders = joined_df.orderBy(col(\"OrderDate\").desc())\n"
      ],
      "metadata": {
        "id": "n6Cx2LfoqdKG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.write.mode(\"overwrite\").partitionBy(\"City\").parquet(\"/content/final_orders_parquet\")\n"
      ],
      "metadata": {
        "id": "3SKBXNa7qn27"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "joined_df.createOrReplaceTempView(\"orders_view\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    SELECT CustomerID, Name, SUM(TotalAmount) AS TotalSales\n",
        "    FROM orders_view\n",
        "    GROUP BY CustomerID, Name\n",
        "\"\"\").show()\n",
        "\n",
        "# Count of products per city\n",
        "spark.sql(\"\"\"\n",
        "    SELECT City, COUNT(Product) AS ProductCount\n",
        "    FROM orders_view\n",
        "    GROUP BY City\n",
        "\"\"\").show()\n",
        "\n",
        "# Top 2 cities by revenue\n",
        "spark.sql(\"\"\"\n",
        "    SELECT City, SUM(TotalAmount) AS CityRevenue\n",
        "    FROM orders_view\n",
        "    GROUP BY City\n",
        "    ORDER BY CityRevenue DESC\n",
        "    LIMIT 2\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiivEadQqoDP",
        "outputId": "3f93e806-0246-446c-ec90-048b98ef5e97"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----------+\n",
            "|CustomerID| Name|TotalSales|\n",
            "+----------+-----+----------+\n",
            "|       101|Aditi|     73000|\n",
            "|       102|Rohan|     50000|\n",
            "|       103|Meena|     10000|\n",
            "|       104|Kabir|     12000|\n",
            "+----------+-----+----------+\n",
            "\n",
            "+---------+------------+\n",
            "|     City|ProductCount|\n",
            "+---------+------------+\n",
            "|Bangalore|           1|\n",
            "|   Mumbai|           2|\n",
            "|    Delhi|           1|\n",
            "|Hyderabad|           1|\n",
            "+---------+------------+\n",
            "\n",
            "+------+-----------+\n",
            "|  City|CityRevenue|\n",
            "+------+-----------+\n",
            "|Mumbai|      73000|\n",
            "| Delhi|      50000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JTcokY9oqy73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}