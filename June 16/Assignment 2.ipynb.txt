{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dee4e9bc-fb70-4b68-aa70-f3ed9d675b9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CourseData\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40285e61-cf28-4033-9510-852c899e76bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imports\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Load CSV files\n",
    "subscriptions = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"file:/Workspace/Shared/subscriptions.csv\")\n",
    "user_activity = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"file:/Workspace/Shared/user_activity.csv\")\n",
    "\n",
    "# Cast date columns\n",
    "subscriptions = subscriptions.withColumn(\"StartDate\", to_date(\"StartDate\")) \\\n",
    "                             .withColumn(\"EndDate\", to_date(\"EndDate\")) \\\n",
    "                             .withColumn(\"PriceUSD\", col(\"PriceUSD\").cast(\"double\")) \\\n",
    "                             .withColumn(\"IsActive\", col(\"IsActive\").cast(\"boolean\")) \\\n",
    "                             .withColumn(\"AutoRenew\", col(\"AutoRenew\").cast(\"boolean\"))\n",
    "\n",
    "user_activity = user_activity.withColumn(\"EventTime\", to_timestamp(\"EventTime\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "530c02ea-d0b0-49b0-9cde-457125c531ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Question A – Engagement Score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "367d65eb-d152-4861-b10f-46f20e18b0e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+------------------+\n|UserID|SubscriptionID|  engagement_score|\n+------+--------------+------------------+\n|  U001|        SUB001|0.6593406593406594|\n|  U002|        SUB002|               1.0|\n|  U003|        SUB003|0.9782608695652174|\n|  U001|        SUB004|2.6373626373626378|\n|  U004|        SUB005|0.3296703296703297|\n+------+--------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question A: Subscription Engagement Score\n",
    "\n",
    "from pyspark.sql.functions import countDistinct, datediff\n",
    "\n",
    "# active_days\n",
    "subscriptions_with_days = subscriptions.withColumn(\"active_days\", datediff(\"EndDate\", \"StartDate\"))\n",
    "\n",
    "# events_per_user\n",
    "events_per_user = user_activity.groupBy(\"UserID\").agg(count(\"*\").alias(\"events_per_user\"))\n",
    "\n",
    "# Join and calculate engagement_score\n",
    "engagement_df = subscriptions_with_days.join(events_per_user, on=\"UserID\", how=\"left\") \\\n",
    "    .fillna(0, subset=[\"events_per_user\"]) \\\n",
    "    .withColumn(\"engagement_score\", (col(\"events_per_user\") / col(\"active_days\")) * col(\"PriceUSD\"))\n",
    "\n",
    "engagement_df.select(\"UserID\", \"SubscriptionID\", \"engagement_score\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c29a69e1-b21b-41f5-ae0b-9a02f4b3820d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Question B – Anomaly Detection via SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ac73fde-7c51-4a59-be53-fade4ec56c1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|UserID|\n+------+\n+------+\n\n+------+\n|UserID|\n+------+\n|  U001|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question B: Anomaly Detection\n",
    "\n",
    "subscriptions.createOrReplaceTempView(\"subscriptions\")\n",
    "user_activity.createOrReplaceTempView(\"user_activity\")\n",
    "\n",
    "# Inactive subscription but recent activity\n",
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT s.UserID\n",
    "FROM subscriptions s\n",
    "JOIN user_activity u ON s.UserID = u.UserID\n",
    "WHERE s.IsActive = false AND u.EventTime > s.EndDate\n",
    "\"\"\").show()\n",
    "\n",
    "# AutoRenew is true but no events in last 30 days\n",
    "spark.sql(\"\"\"\n",
    "SELECT s.UserID\n",
    "FROM subscriptions s\n",
    "LEFT JOIN user_activity u ON s.UserID = u.UserID\n",
    "WHERE s.AutoRenew = true\n",
    "GROUP BY s.UserID\n",
    "HAVING max(u.EventTime) < current_date() - interval 30 days\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6859299-a7c5-4e8b-8c2d-c74a46d4246b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Question C – Delta Lake + Merge Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c128fe6-b3fd-4962-a639-2c38feebd595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+--------+----------+----------+--------+--------+---------+\n|SubscriptionID|UserID|PlanType| StartDate|   EndDate|PriceUSD|IsActive|AutoRenew|\n+--------------+------+--------+----------+----------+--------+--------+---------+\n|        SUB001|  U001|   Basic|2024-01-01|2024-04-01|    30.0|    true|     true|\n|        SUB002|  U002|     Pro|2024-02-15|2024-05-15|    90.0|    true|    false|\n|        SUB004|  U001| Premium|2024-04-05|2024-07-05|   120.0|    true|     true|\n|        SUB005|  U004|   Basic|2024-01-20|2024-04-20|    30.0|   false|    false|\n|        SUB003|  U003|     Pro|2024-03-10|2024-06-10|    95.0|   false|    false|\n+--------------+------+--------+----------+----------+--------+--------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question C: Apply billing fix via MERGE INTO on Delta table\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Save original as Delta\n",
    "subscriptions.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/delta_subscriptions\")\n",
    "\n",
    "# Load Delta Table\n",
    "delta_subs = DeltaTable.forPath(spark, \"/tmp/delta_subscriptions\")\n",
    "\n",
    "# Create updates DataFrame\n",
    "fix_updates = subscriptions.filter((col(\"PlanType\") == \"Pro\") & month(\"StartDate\").between(3, 3)) \\\n",
    "                           .withColumn(\"NewPrice\", col(\"PriceUSD\") + 5) \\\n",
    "                           .select(\"SubscriptionID\", col(\"NewPrice\").alias(\"PriceUSD\"))\n",
    "\n",
    "# Merge\n",
    "delta_subs.alias(\"t\").merge(\n",
    "    fix_updates.alias(\"u\"),\n",
    "    \"t.SubscriptionID = u.SubscriptionID\"\n",
    ").whenMatchedUpdate(set={\"PriceUSD\": \"u.PriceUSD\"}).execute()\n",
    "\n",
    "# Verify\n",
    "delta_subs.toDF().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67b50520-d6a5-4742-8b26-77f0f55b74f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Question D – Time Travel Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "224c7142-a6ae-4615-b88e-94ce321e3f66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+----------------------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n|version|timestamp          |userId          |userName                          |operation|operationParameters                                                                                                                                                                               |job |notebook          |clusterId           |readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |userMetadata|engineInfo                                |\n+-------+-------------------+----------------+----------------------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n|2      |2025-06-16 10:23:45|7928277367239535|azuser3564_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}                                                                                                                    |NULL|{2667377285921564}|0611-043414-4p180ssa|1          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 4103, p25FileSize -> 2158, numDeletionVectorsRemoved -> 1, minFileSize -> 2158, numAddedFiles -> 1, maxFileSize -> 2158, p75FileSize -> 2158, p50FileSize -> 2158, numAddedBytes -> 2158}                                                                                                                                                                                                                                                                                                                                                                                                                                                  |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|1      |2025-06-16 10:23:41|7928277367239535|azuser3564_mml.local@techademy.com|MERGE    |{predicate -> [\"(SubscriptionID#846 = SubscriptionID#131)\"], matchedPredicates -> [{\"actionType\":\"update\"}], statsOnLoad -> false, notMatchedBySourcePredicates -> [], notMatchedPredicates -> []}|NULL|{2667377285921564}|0611-043414-4p180ssa|0          |WriteSerializable|false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 1950, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 1, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 5751, materializeSourceTimeMs -> 343, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 3191, numTargetRowsUpdated -> 1, numOutputRows -> 1, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 1, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 2129}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|0      |2025-06-16 10:23:30|7928277367239535|azuser3564_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                                                                                                                                      |NULL|{2667377285921564}|0611-043414-4p180ssa|NULL       |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 2153}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n+-------+-------------------+----------------+----------------------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n\n+--------------+------+--------+----------+----------+--------+--------+---------+\n|SubscriptionID|UserID|PlanType| StartDate|   EndDate|PriceUSD|IsActive|AutoRenew|\n+--------------+------+--------+----------+----------+--------+--------+---------+\n|        SUB001|  U001|   Basic|2024-01-01|2024-04-01|    30.0|    true|     true|\n|        SUB002|  U002|     Pro|2024-02-15|2024-05-15|    90.0|    true|    false|\n|        SUB003|  U003|     Pro|2024-03-10|2024-06-10|    90.0|   false|    false|\n|        SUB004|  U001| Premium|2024-04-05|2024-07-05|   120.0|    true|     true|\n|        SUB005|  U004|   Basic|2024-01-20|2024-04-20|    30.0|   false|    false|\n+--------------+------+--------+----------+----------+--------+--------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question D: Delta History & Time Travel\n",
    "\n",
    "# View history\n",
    "spark.sql(\"DESCRIBE HISTORY delta.`/tmp/delta_subscriptions`\").show(truncate=False)\n",
    "\n",
    "# Previous version data\n",
    "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/tmp/delta_subscriptions\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c034da49-923e-46ba-b5eb-e54ffe853a38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Question E – Tier Migration Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59823d87-d507-4368-9d88-a2b54ed5045d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------------+\n|UserID|prev_plan|PlanType|        upgrade|\n+------+---------+--------+---------------+\n|  U001|    Basic| Premium|Basic → Premium|\n+------+---------+--------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question E: Tier Migration using lag()\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Window by user and order by StartDate\n",
    "w = Window.partitionBy(\"UserID\").orderBy(\"StartDate\")\n",
    "\n",
    "tier_migration = subscriptions.withColumn(\"prev_plan\", lag(\"PlanType\").over(w)) \\\n",
    "                              .withColumn(\"upgrade\", concat_ws(\" → \", \"prev_plan\", \"PlanType\")) \\\n",
    "                              .filter(col(\"prev_plan\").isNotNull())\n",
    "\n",
    "tier_migration.select(\"UserID\", \"prev_plan\", \"PlanType\", \"upgrade\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f54ff6ef-4690-428f-bb22-8a7fb9a0baa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Question F – Power Users Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc4d118-3312-4fef-8c37-f84298acc388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-----------+\n|UserID|unique_features|login_count|\n+------+---------------+-----------+\n+------+---------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question F: Power Users\n",
    "\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Feature usage & login count\n",
    "activity_summary = user_activity.groupBy(\"UserID\") \\\n",
    "    .agg(\n",
    "        countDistinct(\"FeatureUsed\").alias(\"unique_features\"),\n",
    "        count(when(col(\"EventType\") == \"login\", True)).alias(\"login_count\")\n",
    "    )\n",
    "\n",
    "power_users = activity_summary.filter((col(\"unique_features\") >= 2) & (col(\"login_count\") >= 3))\n",
    "\n",
    "# Save to Delta\n",
    "power_users.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/power_users\")\n",
    "\n",
    "spark.read.format(\"delta\").load(\"/tmp/power_users\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2711dd9f-5179-4c95-9d2a-3201e03755fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Question G – Session Replay View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0354fed6-8c05-4b6a-910f-a708307854ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-------------------+------------------------+\n|UserID|          EventTime|          next_time|session_duration_minutes|\n+------+-------------------+-------------------+------------------------+\n|  U001|2024-04-07 10:22:00|2024-04-10 16:00:00|                  4658.0|\n+------+-------------------+-------------------+------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Question G: Session Replay using login/logout durations\n",
    "\n",
    "from pyspark.sql.functions import lead\n",
    "\n",
    "w = Window.partitionBy(\"UserID\").orderBy(\"EventTime\")\n",
    "\n",
    "# Add next event\n",
    "session_trace = user_activity.withColumn(\"next_event\", lead(\"EventType\").over(w)) \\\n",
    "                             .withColumn(\"next_time\", lead(\"EventTime\").over(w)) \\\n",
    "                             .filter((col(\"EventType\") == \"login\") & (col(\"next_event\") == \"logout\")) \\\n",
    "                             .withColumn(\"session_duration_minutes\", \n",
    "                                         (unix_timestamp(\"next_time\") - unix_timestamp(\"EventTime\")) / 60)\n",
    "\n",
    "session_trace.select(\"UserID\", \"EventTime\", \"next_time\", \"session_duration_minutes\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "June 16-task 2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}