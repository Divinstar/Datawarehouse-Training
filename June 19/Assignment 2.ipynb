{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-VL0ZykyDVJn"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q pyspark==3.5.1 delta-spark==3.1.0\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
        "\n",
        "# Create SparkSession with Delta support\n",
        "from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip\n",
        "\n",
        "builder = SparkSession.builder \\\n",
        "    .appName(\"OnlineCourseAnalytics\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load course_enrollments.csv\n",
        "enrollments_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/content/course_enrollments.csv\")\n",
        "\n",
        "# Load course_catalog.csv\n",
        "catalog_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/content/course_catalog.csv\")\n",
        "\n",
        "# Optional: preview the data\n",
        "enrollments_df.show()\n",
        "catalog_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tZsTASID6Iq",
        "outputId": "8b507e65-b840-41d0-a434-88b0ed9ed81d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+\n",
            "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+\n",
            "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|   4.0|\n",
            "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|\n",
            "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|\n",
            "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|   5.0|\n",
            "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|   4.0|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+\n",
            "\n",
            "+--------+-------------+-------------+------------+\n",
            "|CourseID|   Instructor|DurationHours|       Level|\n",
            "+--------+-------------+-------------+------------+\n",
            "|    C001|Abdullah Khan|            8|    Beginner|\n",
            "|    C002|   Sana Gupta|            5|    Beginner|\n",
            "|    C003| Ibrahim Khan|           10|Intermediate|\n",
            "|    C004|  Zoya Sheikh|            6|    Beginner|\n",
            "+--------+-------------+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, count, when\n",
        "\n",
        "# Flag completed\n",
        "enrollments_df = enrollments_df.withColumn(\"IsCompleted\", when(col(\"ProgressPercent\") == 100, True).otherwise(False))\n",
        "\n",
        "# Group by UserID\n",
        "user_progress_df = enrollments_df.groupBy(\"UserID\").agg(\n",
        "    count(\"*\").alias(\"CoursesEnrolled\"),\n",
        "    avg(\"ProgressPercent\").alias(\"AvgProgressPercent\")\n",
        ")\n",
        "\n",
        "user_progress_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykU-KI-5EW0F",
        "outputId": "20a12373-b8f8-4432-e594-467e0dfd6bab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------+------------------+\n",
            "|UserID|CoursesEnrolled|AvgProgressPercent|\n",
            "+------+---------------+------------------+\n",
            "|  U004|              1|             100.0|\n",
            "|  U002|              1|              45.0|\n",
            "|  U003|              1|             100.0|\n",
            "|  U001|              2|              65.0|\n",
            "+------+---------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropouts: Progress < 50 AND not completed\n",
        "dropouts_df = enrollments_df.filter((col(\"ProgressPercent\") < 50) & col(\"CompletionDate\").isNull())\n",
        "\n",
        "# Register view\n",
        "dropouts_df.createOrReplaceTempView(\"Dropouts\")\n",
        "\n",
        "# Verify\n",
        "spark.sql(\"SELECT * FROM Dropouts\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdk163DAEgCX",
        "outputId": "c0c54e14-7ff3-421d-9f5b-838fba5dfd45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|IsCompleted|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|      false|\n",
            "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|      false|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Join enrollments with catalog\n",
        "joined_df = enrollments_df.join(catalog_df, on=\"CourseID\", how=\"inner\")\n",
        "\n",
        "# Average progress per instructor\n",
        "avg_progress = joined_df.groupBy(\"Instructor\").agg(avg(\"ProgressPercent\").alias(\"AvgProgress\"))\n",
        "avg_progress.show()\n",
        "\n",
        "# Most enrolled course\n",
        "most_enrolled = enrollments_df.groupBy(\"CourseName\").count().orderBy(col(\"count\").desc()).limit(1)\n",
        "most_enrolled_course_name = most_enrolled.collect()[0][\"CourseName\"]\n",
        "\n",
        "# Who teaches it?\n",
        "instructor = joined_df.filter(col(\"CourseName\") == most_enrolled_course_name).select(\"Instructor\").distinct()\n",
        "print(f\"ðŸ‘¨â€ðŸ« Instructor for most enrolled course ({most_enrolled_course_name}):\")\n",
        "instructor.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3wWULNfEgIK",
        "outputId": "839b32a6-2178-4052-bd82-4d6b6815801c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------+\n",
            "|   Instructor|AvgProgress|\n",
            "+-------------+-----------+\n",
            "|  Zoya Sheikh|      100.0|\n",
            "|   Sana Gupta|       45.0|\n",
            "| Ibrahim Khan|       30.0|\n",
            "|Abdullah Khan|      100.0|\n",
            "+-------------+-----------+\n",
            "\n",
            "ðŸ‘¨â€ðŸ« Instructor for most enrolled course (Python Basics):\n",
            "+-------------+\n",
            "|   Instructor|\n",
            "+-------------+\n",
            "|Abdullah Khan|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from delta.tables import DeltaTable\n",
        "\n",
        "enrollments_df.write.format(\"delta\").mode(\"overwrite\").save(\"/content/enrollments_delta\")\n",
        "\n",
        "delta_table = DeltaTable.forPath(spark, \"/content/enrollments_delta\")\n",
        "\n",
        "delta_table.update(\n",
        "    condition=col(\"CourseName\") == \"Python Basics\",\n",
        "    set={\"Rating\": \"5\"}\n",
        ")\n",
        "\n",
        "delta_table.delete(col(\"ProgressPercent\") == 0)\n",
        "\n",
        "spark.sql(\"DROP TABLE IF EXISTS enrollments_delta\")\n",
        "spark.sql(\"CREATE TABLE enrollments_delta USING DELTA LOCATION '/content/enrollments_delta'\")\n",
        "spark.sql(\"DESCRIBE HISTORY enrollments_delta\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYdqOunMEgM6",
        "outputId": "931c6aca-522e-427a-f334-0c1fe19e6a71"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+------+--------+---------+----------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
            "|version|timestamp              |userId|userName|operation|operationParameters                                 |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                              |userMetadata|engineInfo                         |\n",
            "+-------+-----------------------+------+--------+---------+----------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
            "|1      |2025-06-19 07:24:23.075|NULL  |NULL    |UPDATE   |{predicate -> [\"(CourseName#1473 = Python Basics)\"]}|NULL|NULL    |NULL     |0          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 3147, numCopiedRows -> 3, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 6460, numDeletionVectorsUpdated -> 0, scanTimeMs -> 5821, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 3147, rewriteTimeMs -> 634}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
            "|0      |2025-06-19 07:24:03.651|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}              |NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3147}                                                                                                                                                                                                                                                                   |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
            "+-------+-----------------------+------+--------+---------+----------------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import dense_rank, lead\n",
        "\n",
        "# Rank courses by enrollments\n",
        "ranked = enrollments_df.groupBy(\"CourseName\").count()\n",
        "rank_window = Window.orderBy(col(\"count\").desc())\n",
        "ranked = ranked.withColumn(\"Rank\", dense_rank().over(rank_window))\n",
        "ranked.show()\n",
        "\n",
        "# Lead: Next course per user\n",
        "lead_window = Window.partitionBy(\"UserID\").orderBy(\"EnrollDate\")\n",
        "next_course_df = enrollments_df.withColumn(\"NextCourse\", lead(\"CourseName\").over(lead_window))\n",
        "next_course_df.select(\"UserID\", \"CourseName\", \"NextCourse\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHsiXkyqEgRc",
        "outputId": "21b862ee-6ca6-4dd9-90ce-9c538c200b7e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+----+\n",
            "|       CourseName|count|Rank|\n",
            "+-----------------+-----+----+\n",
            "|    Python Basics|    2|   1|\n",
            "|Digital Marketing|    1|   2|\n",
            "|Excel for Finance|    1|   2|\n",
            "|  ML with PySpark|    1|   2|\n",
            "+-----------------+-----+----+\n",
            "\n",
            "+------+-----------------+---------------+\n",
            "|UserID|       CourseName|     NextCourse|\n",
            "+------+-----------------+---------------+\n",
            "|  U001|    Python Basics|ML with PySpark|\n",
            "|  U001|  ML with PySpark|           NULL|\n",
            "|  U002|Excel for Finance|           NULL|\n",
            "|  U003|    Python Basics|           NULL|\n",
            "|  U004|Digital Marketing|           NULL|\n",
            "+------+-----------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "enrollments_df.createOrReplaceTempView(\"Enrollments\")\n",
        "\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW daily_enrollments AS\n",
        "    SELECT EnrollDate, COUNT(*) AS TotalEnrollments\n",
        "    FROM Enrollments\n",
        "    GROUP BY EnrollDate\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW category_performance AS\n",
        "    SELECT Category, AVG(Rating) AS AvgRating\n",
        "    FROM Enrollments\n",
        "    GROUP BY Category\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW top_3_courses AS\n",
        "    SELECT CourseName, COUNT(*) AS Enrollments\n",
        "    FROM Enrollments\n",
        "    GROUP BY CourseName\n",
        "    ORDER BY Enrollments DESC\n",
        "    LIMIT 3\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "spark.sql(\"SELECT * FROM top_3_courses\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m14ueEQvEgVM",
        "outputId": "3bdd6a00-e335-47ba-dc5b-3f4d23de4070"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+\n",
            "|       CourseName|Enrollments|\n",
            "+-----------------+-----------+\n",
            "|    Python Basics|          2|\n",
            "|Digital Marketing|          1|\n",
            "|Excel for Finance|          1|\n",
            "+-----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"/content/enrollments_delta\").show()\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "timestamp = (datetime.now() - timedelta(minutes=1)).isoformat(timespec=\"seconds\")\n",
        "\n",
        "spark.read.format(\"delta\").option(\"timestampAsOf\", timestamp).load(\"/content/enrollments_delta\").show()\n",
        "\n",
        "summary_df = enrollments_df.groupBy(\"CourseName\").agg(\n",
        "    count(\"*\").alias(\"TotalEnrollments\"),\n",
        "    avg(\"Rating\").alias(\"AvgRating\"),\n",
        "    avg(\"ProgressPercent\").alias(\"AvgProgress\")\n",
        ")\n",
        "summary_df.show()\n",
        "\n",
        "enrollments_df.write.partitionBy(\"Category\").mode(\"overwrite\").json(\"/content/enrollment_json\")\n",
        "summary_df.write.mode(\"overwrite\").parquet(\"/content/summary_report.parquet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL8mCgMpEgZQ",
        "outputId": "51b13b3a-4140-402c-a99c-a611641f26b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|IsCompleted|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|   4.0|       true|\n",
            "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|      false|\n",
            "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|      false|\n",
            "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|   5.0|       true|\n",
            "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|   4.0|       true|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|IsCompleted|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|   4.0|       true|\n",
            "|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|  NULL|      false|\n",
            "|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|  NULL|      false|\n",
            "|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|   5.0|       true|\n",
            "|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|   4.0|       true|\n",
            "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+-----------+\n",
            "\n",
            "+-----------------+----------------+---------+-----------+\n",
            "|       CourseName|TotalEnrollments|AvgRating|AvgProgress|\n",
            "+-----------------+----------------+---------+-----------+\n",
            "|Digital Marketing|               1|      4.0|      100.0|\n",
            "|    Python Basics|               2|      4.5|      100.0|\n",
            "|Excel for Finance|               1|     NULL|       45.0|\n",
            "|  ML with PySpark|               1|     NULL|       30.0|\n",
            "+-----------------+----------------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTddoRbwEgdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzmABOlIEgha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}