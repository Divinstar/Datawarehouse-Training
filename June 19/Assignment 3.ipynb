{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z2HplLlkTYoT"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q pyspark==3.5.1 delta-spark==3.1.0\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
        "\n",
        "# Create SparkSession with Delta support\n",
        "from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip\n",
        "\n",
        "builder = SparkSession.builder \\\n",
        "    .appName(\"OnlineCourseAnalytics\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RetailInventoryDeltaLake\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "inventory_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"inventory_supply.csv\")\n",
        "\n",
        "\n",
        "restock_logs_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"restock_logs.csv\")\n",
        "\n",
        "inventory_df.show()\n",
        "restock_logs_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiNoaH7fT_-5",
        "outputId": "b0819f41-2bcb-4a2e-d487-c92456fdb391"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "\n",
            "+------+-----------+-------------+\n",
            "|ItemID|RestockDate|QuantityAdded|\n",
            "+------+-----------+-------------+\n",
            "|  I002| 2024-04-20|           10|\n",
            "|  I005| 2024-04-22|            5|\n",
            "|  I001| 2024-04-25|           20|\n",
            "+------+-----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, count, when, col  # <-- col added here\n",
        "\n",
        "# 1. Average price per supplier\n",
        "avg_price_by_supplier = inventory_df.groupBy(\"Supplier\").agg(avg(\"UnitPrice\").alias(\"AvgPrice\"))\n",
        "avg_price_by_supplier.show()\n",
        "\n",
        "# 2. Suppliers offering items below average price in their category\n",
        "category_avg = inventory_df.groupBy(\"Category\").agg(avg(\"UnitPrice\").alias(\"CategoryAvg\"))\n",
        "below_avg_items = inventory_df.join(category_avg, on=\"Category\") \\\n",
        "    .filter(col(\"UnitPrice\") < col(\"CategoryAvg\"))\n",
        "below_avg_items.select(\"Supplier\", \"ItemName\", \"UnitPrice\", \"Category\", \"CategoryAvg\").show()\n",
        "\n",
        "# 3. Tag suppliers with Good Deal if >50% of their items are below market average\n",
        "flagged = inventory_df.join(category_avg, \"Category\") \\\n",
        "    .withColumn(\"IsGoodDeal\", (col(\"UnitPrice\") < col(\"CategoryAvg\")).cast(\"int\"))\n",
        "\n",
        "good_deal_tagged = flagged.groupBy(\"Supplier\") \\\n",
        "    .agg((avg(\"IsGoodDeal\") * 100).alias(\"BelowAvgPercent\")) \\\n",
        "    .withColumn(\"Tag\", when(col(\"BelowAvgPercent\") > 50, \"Good Deal\").otherwise(\"\"))\n",
        "\n",
        "good_deal_tagged.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHFGb-WaUE-p",
        "outputId": "ee3e7ff5-6fb7-4831-d456-57fb18373bf8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "| Supplier|AvgPrice|\n",
            "+---------+--------+\n",
            "|   AVTech| 30000.0|\n",
            "|TechWorld| 70000.0|\n",
            "|PrintFast|  8000.0|\n",
            "| FreezeIt| 25000.0|\n",
            "|  ChairCo|  6000.0|\n",
            "+---------+--------+\n",
            "\n",
            "+---------+--------+---------+-----------+-----------+\n",
            "| Supplier|ItemName|UnitPrice|   Category|CategoryAvg|\n",
            "+---------+--------+---------+-----------+-----------+\n",
            "|   AVTech|  LED TV|    30000|Electronics|    36000.0|\n",
            "|PrintFast| Printer|     8000|Electronics|    36000.0|\n",
            "+---------+--------+---------+-----------+-----------+\n",
            "\n",
            "+---------+---------------+---------+\n",
            "| Supplier|BelowAvgPercent|      Tag|\n",
            "+---------+---------------+---------+\n",
            "|   AVTech|          100.0|Good Deal|\n",
            "|TechWorld|            0.0|         |\n",
            "|PrintFast|          100.0|Good Deal|\n",
            "| FreezeIt|            0.0|         |\n",
            "|  ChairCo|            0.0|         |\n",
            "+---------+---------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3rd\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "cost_df = inventory_df.withColumn(\"TotalStockValue\", col(\"StockQty\") * col(\"UnitPrice\"))\n",
        "cost_df.show()\n",
        "\n",
        "top_items = cost_df.orderBy(col(\"TotalStockValue\").desc()).limit(3)\n",
        "top_items.show()\n",
        "\n",
        "output_path = \"/mnt/data/top_inventory_items_by_warehouse\"\n",
        "top_items.write.mode(\"overwrite\").partitionBy(\"Warehouse\").parquet(output_path)\n",
        "\n",
        "print(f\"âœ… Exported to Parquet at: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqQi_1M4Uktn",
        "outputId": "52eafcae-cf67-4ec0-b3b2-695aa6b330d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+---------------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|TotalStockValue|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+---------------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|        1500000|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|         700000|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|         240000|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|         125000|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       3|           5|   2024-03-30|     8000|PrintFast|          24000|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+---------------+\n",
            "\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+---------------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|TotalStockValue|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+---------------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      50|          20|   2024-03-15|    30000|   AVTech|        1500000|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      10|          15|   2024-04-01|    70000|TechWorld|         700000|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|         240000|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+---------------+\n",
            "\n",
            "âœ… Exported to Parquet at: /mnt/data/top_inventory_items_by_warehouse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 th\n",
        "from pyspark.sql.functions import avg, sum\n",
        "\n",
        "items_per_warehouse = inventory_df.groupBy(\"Warehouse\").count().withColumnRenamed(\"count\", \"ItemCount\")\n",
        "items_per_warehouse.show()\n",
        "\n",
        "avg_stock_per_category = inventory_df.groupBy(\"Warehouse\", \"Category\") \\\n",
        "    .agg(avg(\"StockQty\").alias(\"AvgStock\"))\n",
        "avg_stock_per_category.show()\n",
        "\n",
        "total_stock_per_warehouse = inventory_df.groupBy(\"Warehouse\") \\\n",
        "    .agg(sum(\"StockQty\").alias(\"TotalStock\")) \\\n",
        "    .filter(col(\"TotalStock\") < 100)\n",
        "total_stock_per_warehouse.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab4XIWh_Usev",
        "outputId": "3e743b62-b4d6-4a75-a4a7-d4f98e414b37"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+\n",
            "| Warehouse|ItemCount|\n",
            "+----------+---------+\n",
            "|WarehouseA|        2|\n",
            "|WarehouseC|        1|\n",
            "|WarehouseB|        2|\n",
            "+----------+---------+\n",
            "\n",
            "+----------+-----------+--------+\n",
            "| Warehouse|   Category|AvgStock|\n",
            "+----------+-----------+--------+\n",
            "|WarehouseB|Electronics|     6.5|\n",
            "|WarehouseA|  Furniture|    40.0|\n",
            "|WarehouseC| Appliances|     5.0|\n",
            "|WarehouseA|Electronics|    50.0|\n",
            "+----------+-----------+--------+\n",
            "\n",
            "+----------+----------+\n",
            "| Warehouse|TotalStock|\n",
            "+----------+----------+\n",
            "|WarehouseA|        90|\n",
            "|WarehouseC|         5|\n",
            "|WarehouseB|        13|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5th\n",
        "from delta.tables import DeltaTable\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "import os\n",
        "\n",
        "# 1. Save as Delta table\n",
        "delta_path = \"/mnt/data/retail_inventory\"\n",
        "inventory_df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
        "\n",
        "# Load as DeltaTable object for update/delete\n",
        "retail_inventory = DeltaTable.forPath(spark, delta_path)\n",
        "\n",
        "# 2. Update stock of 'Laptop' to 20\n",
        "retail_inventory.update(\n",
        "    condition=col(\"ItemName\") == \"Laptop\",\n",
        "    set={\"StockQty\": expr(\"20\")}\n",
        ")\n",
        "\n",
        "# 3. Delete any item with StockQty = 0\n",
        "retail_inventory.delete(condition=col(\"StockQty\") == 0)\n",
        "\n",
        "# 4. View table history\n",
        "spark.sql(f\"DESCRIBE HISTORY delta.`{delta_path}`\").show(truncate=False)\n",
        "\n",
        "# Bonus: Query previous version (if needed)\n",
        "# spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfSUGSCSVE_m",
        "outputId": "a18513f9-84c9-4b05-9966-d6b04d846bca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+------+--------+---------+-------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
            "|version|timestamp              |userId|userName|operation|operationParameters                        |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                              |userMetadata|engineInfo                         |\n",
            "+-------+-----------------------+------+--------+---------+-------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
            "|2      |2025-06-19 08:37:31.395|NULL  |NULL    |UPDATE   |{predicate -> [\"(ItemName#2879 = Laptop)\"]}|NULL|NULL    |NULL     |1          |Serializable  |false        |{numRemovedFiles -> 1, numRemovedBytes -> 2784, numCopiedRows -> 4, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 6449, numDeletionVectorsUpdated -> 0, scanTimeMs -> 5859, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 2784, rewriteTimeMs -> 587}|NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
            "|1      |2025-06-19 08:37:15.268|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}     |NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 2784}                                                                                                                                                                                                                                                                   |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
            "|0      |2025-06-19 08:36:02.545|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}     |NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 2784}                                                                                                                                                                                                                                                                   |NULL        |Apache-Spark/3.5.1 Delta-Lake/3.1.0|\n",
            "+-------+-----------------------+------+--------+---------+-------------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6th\n",
        "from pyspark.sql.functions import col, expr, lit\n",
        "\n",
        "# Load Delta table\n",
        "delta_path = \"/mnt/data/retail_inventory\"\n",
        "inventory_delta = DeltaTable.forPath(spark, delta_path)\n",
        "\n",
        "# Read current Delta table as DataFrame\n",
        "current_inventory = inventory_delta.toDF()\n",
        "\n",
        "# Join with restock logs\n",
        "updated_stock = current_inventory.alias(\"inv\").join(\n",
        "    restock_logs_df.alias(\"log\"),\n",
        "    col(\"inv.ItemID\") == col(\"log.ItemID\"),\n",
        "    \"inner\"\n",
        ").withColumn(\"NewStockQty\", col(\"inv.StockQty\") + col(\"log.QuantityAdded\")) \\\n",
        " .withColumn(\"RestockedRecently\", lit(True)) \\\n",
        " .select(\n",
        "     col(\"inv.ItemID\"),\n",
        "     col(\"inv.ItemName\"),\n",
        "     col(\"inv.Category\"),\n",
        "     col(\"inv.Warehouse\"),\n",
        "     col(\"NewStockQty\").alias(\"StockQty\"),\n",
        "     col(\"inv.ReorderLevel\"),\n",
        "     col(\"inv.LastRestocked\"),\n",
        "     col(\"inv.UnitPrice\"),\n",
        "     col(\"inv.Supplier\"),\n",
        "     col(\"RestockedRecently\")\n",
        " )\n",
        "\n",
        "# Write updated data using MERGE INTO\n",
        "inventory_delta.alias(\"target\").merge(\n",
        "    updated_stock.alias(\"source\"),\n",
        "    \"target.ItemID = source.ItemID\"\n",
        ").whenMatchedUpdate(set={\n",
        "    \"StockQty\": \"source.StockQty\",\n",
        "    \"ItemName\": \"source.ItemName\",\n",
        "    \"Category\": \"source.Category\",\n",
        "    \"Warehouse\": \"source.Warehouse\",\n",
        "    \"ReorderLevel\": \"source.ReorderLevel\",\n",
        "    \"LastRestocked\": \"source.LastRestocked\",\n",
        "    \"UnitPrice\": \"source.UnitPrice\",\n",
        "    \"Supplier\": \"source.Supplier\"\n",
        "}).execute()\n",
        "\n",
        "# Show updated inventory\n",
        "inventory_delta.toDF().show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBf5Hr5mVmJQ",
        "outputId": "61f400e8-3ba8-443e-b0ae-9248b3518d0b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice| Supplier|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      70|          20|   2024-03-15|    30000|   AVTech|\n",
            "|  I002|      Laptop|Electronics|WarehouseB|      30|          15|   2024-04-01|    70000|TechWorld|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000|  ChairCo|\n",
            "|  I004|Refrigerator| Appliances|WarehouseC|       5|          10|   2024-02-20|    25000| FreezeIt|\n",
            "|  I005|     Printer|Electronics|WarehouseB|       8|           5|   2024-03-30|     8000|PrintFast|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "inventory_view_df = DeltaTable.forPath(spark, \"/mnt/data/retail_inventory\").toDF()\n",
        "\n",
        "summary_df = inventory_view_df \\\n",
        "    .withColumn(\"NeedsReorder\", col(\"StockQty\") < col(\"ReorderLevel\")) \\\n",
        "    .withColumn(\"TotalStockValue\", col(\"StockQty\") * col(\"UnitPrice\"))\n",
        "\n",
        "summary_df.createOrReplaceTempView(\"inventory_summary\")\n",
        "\n",
        "spark.sql(\"SELECT ItemName, Category, StockQty, NeedsReorder, TotalStockValue FROM inventory_summary\").show()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW supplier_leaderboard AS\n",
        "    SELECT Supplier, ROUND(AVG(UnitPrice), 2) AS AvgPrice\n",
        "    FROM inventory_summary\n",
        "    GROUP BY Supplier\n",
        "    ORDER BY AvgPrice DESC\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM supplier_leaderboard\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fQu2Or_VwHf",
        "outputId": "5bb0de14-1a81-4e85-816b-e8a43f66a778"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+--------+------------+---------------+\n",
            "|    ItemName|   Category|StockQty|NeedsReorder|TotalStockValue|\n",
            "+------------+-----------+--------+------------+---------------+\n",
            "|      LED TV|Electronics|      70|       false|        2100000|\n",
            "|      Laptop|Electronics|      30|       false|        2100000|\n",
            "|Office Chair|  Furniture|      40|       false|         240000|\n",
            "|Refrigerator| Appliances|       5|        true|         125000|\n",
            "|     Printer|Electronics|       8|       false|          64000|\n",
            "+------------+-----------+--------+------------+---------------+\n",
            "\n",
            "+---------+--------+\n",
            "| Supplier|AvgPrice|\n",
            "+---------+--------+\n",
            "|TechWorld| 70000.0|\n",
            "|   AVTech| 30000.0|\n",
            "| FreezeIt| 25000.0|\n",
            "|PrintFast|  8000.0|\n",
            "|  ChairCo|  6000.0|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8th\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "inv_df = DeltaTable.forPath(spark, \"/mnt/data/retail_inventory\").toDF()\n",
        "\n",
        "categorized_df = inv_df.withColumn(\n",
        "    \"StockStatus\",\n",
        "    when(col(\"StockQty\") > 2 * col(\"ReorderLevel\"), \"Overstocked\").otherwise(\"LowStock\")\n",
        ")\n",
        "\n",
        "categorized_df.select(\"ItemName\", \"StockQty\", \"ReorderLevel\", \"StockStatus\").show()\n",
        "\n",
        "overstocked_filter = categorized_df.filter(col(\"StockStatus\") == \"Overstocked\")\n",
        "print(\"Using .filter():\")\n",
        "overstocked_filter.show()\n",
        "\n",
        "overstocked_where = categorized_df.where(col(\"StockStatus\") == \"Overstocked\")\n",
        "print(\"Using .where():\")\n",
        "overstocked_where.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPcalCa4WWVW",
        "outputId": "071fafac-4f29-4845-9f1d-d22476ef710b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+------------+-----------+\n",
            "|    ItemName|StockQty|ReorderLevel|StockStatus|\n",
            "+------------+--------+------------+-----------+\n",
            "|      LED TV|      70|          20|Overstocked|\n",
            "|      Laptop|      30|          15|   LowStock|\n",
            "|Office Chair|      40|          10|Overstocked|\n",
            "|Refrigerator|       5|          10|   LowStock|\n",
            "|     Printer|       8|           5|   LowStock|\n",
            "+------------+--------+------------+-----------+\n",
            "\n",
            "Using .filter():\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+-----------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice|Supplier|StockStatus|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+-----------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      70|          20|   2024-03-15|    30000|  AVTech|Overstocked|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000| ChairCo|Overstocked|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+-----------+\n",
            "\n",
            "Using .where():\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+-----------+\n",
            "|ItemID|    ItemName|   Category| Warehouse|StockQty|ReorderLevel|LastRestocked|UnitPrice|Supplier|StockStatus|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+-----------+\n",
            "|  I001|      LED TV|Electronics|WarehouseA|      70|          20|   2024-03-15|    30000|  AVTech|Overstocked|\n",
            "|  I003|Office Chair|  Furniture|WarehouseA|      40|          10|   2024-03-25|     6000| ChairCo|Overstocked|\n",
            "+------+------------+-----------+----------+--------+------------+-------------+---------+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month, current_date, datediff\n",
        "\n",
        "feature_df = DeltaTable.forPath(spark, \"/mnt/data/retail_inventory\").toDF()\n",
        "\n",
        "feature_df = feature_df.withColumn(\"RestockMonth\", month(col(\"LastRestocked\")))\n",
        "\n",
        "feature_df = feature_df.withColumn(\"StockAge\", datediff(current_date(), col(\"LastRestocked\")))\n",
        "\n",
        "feature_df = feature_df.withColumn(\n",
        "    \"StockAgeBucket\",\n",
        "    when(col(\"StockAge\") <= 30, \"New\")\n",
        "    .when(col(\"StockAge\") <= 90, \"Moderate\")\n",
        "    .otherwise(\"Stale\")\n",
        ")\n",
        "\n",
        "\n",
        "feature_df.select(\"ItemName\", \"LastRestocked\", \"RestockMonth\", \"StockAge\", \"StockAgeBucket\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gx1lkOTWjsw",
        "outputId": "29b1a749-618a-4754-d3c7-e70c1ce33350"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------+------------+--------+--------------+\n",
            "|    ItemName|LastRestocked|RestockMonth|StockAge|StockAgeBucket|\n",
            "+------------+-------------+------------+--------+--------------+\n",
            "|      LED TV|   2024-03-15|           3|     461|         Stale|\n",
            "|      Laptop|   2024-04-01|           4|     444|         Stale|\n",
            "|Office Chair|   2024-03-25|           3|     451|         Stale|\n",
            "|Refrigerator|   2024-02-20|           2|     485|         Stale|\n",
            "|     Printer|   2024-03-30|           3|     446|         Stale|\n",
            "+------------+-------------+------------+--------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 export it\n",
        "stale_items_df = feature_df.filter(col(\"StockAgeBucket\") == \"Stale\")\n",
        "\n",
        "stale_items_df.write.mode(\"overwrite\").option(\"header\", True).csv(\"/mnt/data/export/inventory/stale_items/csv\")\n",
        "stale_items_df.write.mode(\"overwrite\").json(\"/mnt/data/export/inventory/stale_items/json\")\n",
        "stale_items_df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/data/export/inventory/stale_items/delta\")\n",
        "\n",
        "print(\"âœ… Exports complete! Formats saved at:\")\n",
        "print(\"- CSV:    /mnt/data/export/inventory/stale_items/csv\")\n",
        "print(\"- JSON:   /mnt/data/export/inventory/stale_items/json\")\n",
        "print(\"- DELTA:  /mnt/data/export/inventory/stale_items/delta\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LYoyPy3W2Wb",
        "outputId": "af98251b-f587-4acf-b133-62fcd9f07017"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Exports complete! Formats saved at:\n",
            "- CSV:    /mnt/data/export/inventory/stale_items/csv\n",
            "- JSON:   /mnt/data/export/inventory/stale_items/json\n",
            "- DELTA:  /mnt/data/export/inventory/stale_items/delta\n"
          ]
        }
      ]
    }
  ]
}