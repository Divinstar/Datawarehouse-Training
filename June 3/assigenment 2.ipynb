{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mHCcSuh3N_HB",
        "outputId": "172ee130-4c55-4057-937e-71f57574825b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas Head:\n",
            "    OrderID    CustomerName ProductCategory  Amount   OrderDate DeliveryStatus  \\\n",
            "0     2824   Donald Walker           Books  783.04  2024-12-26       Returned   \n",
            "1     7912    Brandon Hall       Groceries  905.00  2024-09-12      Cancelled   \n",
            "2     4611    Donald Booth         Fashion  657.96  2025-01-12       Returned   \n",
            "3     3547  Phillip Garcia         Fashion  606.89  2024-03-24       Returned   \n",
            "4     8527    Valerie Gray            Toys   77.87  2024-08-04      Delivered   \n",
            "\n",
            "   Discount              City  PaymentMode CustomerSince  \n",
            "0      0.15      Lake Joyside  Credit Card    2020-10-15  \n",
            "1      0.03     New Jamesside       Wallet    2022-03-15  \n",
            "2      0.01      Lake Roberto       Wallet    2021-08-07  \n",
            "3      0.15  West Melanieview       Wallet    2020-08-08  \n",
            "4      0.17         Mariastad         Cash    2022-11-15  \n",
            "Pandas Tail:\n",
            "      OrderID     CustomerName ProductCategory  Amount   OrderDate  \\\n",
            "495     2930     Jaime Harris         Fashion  680.00  2025-02-16   \n",
            "496     7980       Dawn Wyatt         Fashion  285.32  2024-04-26   \n",
            "497     7770    Kristin White       Groceries  792.11  2024-08-10   \n",
            "498     6641  Jennifer Taylor            Toys  578.49  2025-04-03   \n",
            "499     4513      Rachel Owen     Electronics  904.97  2024-09-21   \n",
            "\n",
            "    DeliveryStatus  Discount             City PaymentMode CustomerSince  \n",
            "495       Returned      0.20      Robertville        Cash    2021-01-28  \n",
            "496      Cancelled      0.06       Cherylfurt         UPI    2021-04-14  \n",
            "497       Returned      0.07         Kingport         UPI    2022-11-16  \n",
            "498      Delivered      0.10  Lake Jerryburgh        Cash    2020-11-04  \n",
            "499      Delivered      0.12    East Paultown        Cash    2020-10-21  \n",
            "Pandas Info:\n",
            " OrderID              int64\n",
            "CustomerName        object\n",
            "ProductCategory     object\n",
            "Amount             float64\n",
            "OrderDate           object\n",
            "DeliveryStatus      object\n",
            "Discount           float64\n",
            "City                object\n",
            "PaymentMode         object\n",
            "CustomerSince       object\n",
            "dtype: object\n",
            "+-------+--------------+---------------+------+----------+--------------+--------+----------------+-----------+-------------+\n",
            "|OrderID|  CustomerName|ProductCategory|Amount| OrderDate|DeliveryStatus|Discount|            City|PaymentMode|CustomerSince|\n",
            "+-------+--------------+---------------+------+----------+--------------+--------+----------------+-----------+-------------+\n",
            "|   2824| Donald Walker|          Books|783.04|2024-12-26|      Returned|    0.15|    Lake Joyside|Credit Card|   2020-10-15|\n",
            "|   7912|  Brandon Hall|      Groceries| 905.0|2024-09-12|     Cancelled|    0.03|   New Jamesside|     Wallet|   2022-03-15|\n",
            "|   4611|  Donald Booth|        Fashion|657.96|2025-01-12|      Returned|    0.01|    Lake Roberto|     Wallet|   2021-08-07|\n",
            "|   3547|Phillip Garcia|        Fashion|606.89|2024-03-24|      Returned|    0.15|West Melanieview|     Wallet|   2020-08-08|\n",
            "|   8527|  Valerie Gray|           Toys| 77.87|2024-08-04|     Delivered|    0.17|       Mariastad|       Cash|   2022-11-15|\n",
            "+-------+--------------+---------------+------+----------+--------------+--------+----------------+-----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- CustomerName: string (nullable = true)\n",
            " |-- ProductCategory: string (nullable = true)\n",
            " |-- Amount: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            " |-- DeliveryStatus: string (nullable = true)\n",
            " |-- Discount: double (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- PaymentMode: string (nullable = true)\n",
            " |-- CustomerSince: date (nullable = true)\n",
            "\n",
            "Dask Head:\n",
            "    OrderID    CustomerName ProductCategory  Amount   OrderDate DeliveryStatus  \\\n",
            "0     2824   Donald Walker           Books  783.04  2024-12-26       Returned   \n",
            "1     7912    Brandon Hall       Groceries  905.00  2024-09-12      Cancelled   \n",
            "2     4611    Donald Booth         Fashion  657.96  2025-01-12       Returned   \n",
            "3     3547  Phillip Garcia         Fashion  606.89  2024-03-24       Returned   \n",
            "4     8527    Valerie Gray            Toys   77.87  2024-08-04      Delivered   \n",
            "\n",
            "   Discount              City  PaymentMode CustomerSince  \n",
            "0      0.15      Lake Joyside  Credit Card    2020-10-15  \n",
            "1      0.03     New Jamesside       Wallet    2022-03-15  \n",
            "2      0.01      Lake Roberto       Wallet    2021-08-07  \n",
            "3      0.15  West Melanieview       Wallet    2020-08-08  \n",
            "4      0.17         Mariastad         Cash    2022-11-15  \n",
            "Dask Tail:\n",
            "      OrderID     CustomerName ProductCategory  Amount   OrderDate  \\\n",
            "495     2930     Jaime Harris         Fashion  680.00  2025-02-16   \n",
            "496     7980       Dawn Wyatt         Fashion  285.32  2024-04-26   \n",
            "497     7770    Kristin White       Groceries  792.11  2024-08-10   \n",
            "498     6641  Jennifer Taylor            Toys  578.49  2025-04-03   \n",
            "499     4513      Rachel Owen     Electronics  904.97  2024-09-21   \n",
            "\n",
            "    DeliveryStatus  Discount             City PaymentMode CustomerSince  \n",
            "495       Returned      0.20      Robertville        Cash    2021-01-28  \n",
            "496      Cancelled      0.06       Cherylfurt         UPI    2021-04-14  \n",
            "497       Returned      0.07         Kingport         UPI    2022-11-16  \n",
            "498      Delivered      0.10  Lake Jerryburgh        Cash    2020-11-04  \n",
            "499      Delivered      0.12    East Paultown        Cash    2020-10-21  \n",
            "Dask dtypes:\n",
            " OrderID                      int64\n",
            "CustomerName       string[pyarrow]\n",
            "ProductCategory    string[pyarrow]\n",
            "Amount                     float64\n",
            "OrderDate          string[pyarrow]\n",
            "DeliveryStatus     string[pyarrow]\n",
            "Discount                   float64\n",
            "City               string[pyarrow]\n",
            "PaymentMode        string[pyarrow]\n",
            "CustomerSince      string[pyarrow]\n",
            "dtype: object\n",
            "DeliveryStatus\n",
            "Order Cancelled    149\n",
            "Delivered          119\n",
            "Returned           117\n",
            "Pending            115\n",
            "Name: count, dtype: int64\n",
            "ProductCategory\n",
            "Books          568.600377\n",
            "Electronics    551.745000\n",
            "Fashion        500.630824\n",
            "Groceries      459.517864\n",
            "Toys           534.283750\n",
            "Name: Amount, dtype: float64\n",
            "City\n",
            "Adammouth         72.76\n",
            "Alexisborough    961.35\n",
            "Alfredview       973.20\n",
            "Allenbury        682.47\n",
            "Amandaside       838.13\n",
            "                  ...  \n",
            "Willismouth      205.59\n",
            "Wilsonton        824.82\n",
            "Woodmouth         73.47\n",
            "Wrightville      610.71\n",
            "Youngbury        372.95\n",
            "Name: Amount, Length: 489, dtype: float64\n",
            "+---------------+-----+\n",
            "| DeliveryStatus|count|\n",
            "+---------------+-----+\n",
            "|       Returned|  117|\n",
            "|      Delivered|  119|\n",
            "|Order Cancelled|  149|\n",
            "|        Pending|  115|\n",
            "+---------------+-----+\n",
            "\n",
            "+---------------+------------------+\n",
            "|ProductCategory|       avg(Amount)|\n",
            "+---------------+------------------+\n",
            "|        Fashion|500.63082352941205|\n",
            "|      Groceries|459.51786407767014|\n",
            "|    Electronics| 551.7450000000002|\n",
            "|          Books| 568.6003773584907|\n",
            "|           Toys| 534.2837499999999|\n",
            "+---------------+------------------+\n",
            "\n",
            "+----------------+-----------+\n",
            "|            City|sum(Amount)|\n",
            "+----------------+-----------+\n",
            "|     Ramseymouth|     761.06|\n",
            "|East Edwardshire|     291.26|\n",
            "|    Lake Douglas|     975.09|\n",
            "|      Thomasberg|     882.68|\n",
            "| South Colinstad|     786.27|\n",
            "|     Laurenville|     383.26|\n",
            "|        Seanbury|     814.39|\n",
            "|      Gordonport|     514.99|\n",
            "|  West Dawnmouth|       12.8|\n",
            "|   Williamsmouth|      10.78|\n",
            "|     Sheilaville|     981.05|\n",
            "|       Mollybury|     222.02|\n",
            "|       Perezfort|     917.55|\n",
            "| Lake Jerrymouth|     404.01|\n",
            "|       Lisaville|      45.69|\n",
            "|     Port Willie|     788.13|\n",
            "|  South Samantha|     229.46|\n",
            "|Port Nicoleshire|     133.78|\n",
            "|Lake Rebeccabury|     891.66|\n",
            "|      Valdezberg|     424.96|\n",
            "+----------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "DeliveryStatus\n",
            "Delivered          119\n",
            "Order Cancelled    149\n",
            "Pending            115\n",
            "Returned           117\n",
            "Name: count, dtype: int64[pyarrow]\n",
            "ProductCategory\n",
            "Books          568.600377\n",
            "Electronics    551.745000\n",
            "Fashion        500.630824\n",
            "Groceries      459.517864\n",
            "Toys           534.283750\n",
            "Name: Amount, dtype: float64\n",
            "City\n",
            "Adammouth         72.76\n",
            "Alexisborough    961.35\n",
            "Alfredview       973.20\n",
            "Allenbury        682.47\n",
            "Amandaside       838.13\n",
            "                  ...  \n",
            "Willismouth      205.59\n",
            "Wilsonton        824.82\n",
            "Woodmouth         73.47\n",
            "Wrightville      610.71\n",
            "Youngbury        372.95\n",
            "Name: Amount, Length: 489, dtype: float64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'LocIndexer' object does not support item assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6995a3a486c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# ---- Dask ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mdask_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'City'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0mdask_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdask_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'City'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Unknown'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'LocIndexer' object does not support item assignment"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# SETUP: Install Dependencies\n",
        "# =============================\n",
        "\n",
        "!pip install -q pyspark dask pandas\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "from pyspark.sql.functions import col, when, year, month, current_date, datediff, to_date, explode, get_json_object, udf\n",
        "from pyspark.sql.types import StringType\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "# =============================\n",
        "# LOAD DATA\n",
        "# =============================\n",
        "\n",
        "# ---- Using Pandas ----\n",
        "pandas_df = pd.read_csv('Sales_Dataset__500_Records_.csv')\n",
        "\n",
        "# ---- Using PySpark ----\n",
        "spark = SparkSession.builder.appName(\"SalesAnalysis\").getOrCreate()\n",
        "spark_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv('Sales_Dataset__500_Records_.csv')\n",
        "\n",
        "# ---- Using Dask ----\n",
        "dask_df = dd.read_csv('Sales_Dataset__500_Records_.csv')\n",
        "\n",
        "# =============================\n",
        "# TASK 1: DataFrame Creation and Inspection\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "print(\"Pandas Head:\\n\", pandas_df.head())\n",
        "print(\"Pandas Tail:\\n\", pandas_df.tail())\n",
        "print(\"Pandas Info:\\n\", pandas_df.dtypes)\n",
        "\n",
        "# ---- PySpark ----\n",
        "spark_df.show(5)\n",
        "spark_df.printSchema()\n",
        "\n",
        "# ---- Dask ----\n",
        "print(\"Dask Head:\\n\", dask_df.head())\n",
        "print(\"Dask Tail:\\n\", dask_df.tail())\n",
        "print(\"Dask dtypes:\\n\", dask_df.dtypes)\n",
        "\n",
        "# =============================\n",
        "# TASK 2: Selection, Renaming, and Filtering\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "pandas_selected = pandas_df[['OrderID', 'CustomerName', 'Amount']].copy()\n",
        "pandas_selected.rename(columns={'Amount': 'OrderAmount'}, inplace=True)\n",
        "filtered_pandas = pandas_selected[pandas_selected['OrderAmount'] > 500]\n",
        "\n",
        "# ---- PySpark ----\n",
        "spark_selected = spark_df.select(\"OrderID\", \"CustomerName\", \"Amount\").withColumnRenamed(\"Amount\", \"OrderAmount\")\n",
        "spark_filtered = spark_selected.filter(col(\"OrderAmount\") > 500)\n",
        "\n",
        "# ---- Dask ----\n",
        "dask_selected = dask_df[['OrderID', 'CustomerName', 'Amount']].rename(columns={'Amount': 'OrderAmount'})\n",
        "dask_filtered = dask_selected[dask_selected['OrderAmount'] > 500]\n",
        "\n",
        "# =============================\n",
        "# TASK 3: Data Manipulation\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "pandas_df.drop(columns=['CustomerSince'], inplace=True)\n",
        "pandas_df['FinalAmount'] = pandas_df['Amount'] - (pandas_df['Amount'] * pandas_df['Discount'])\n",
        "pandas_df.sort_values(by='FinalAmount', ascending=False, inplace=True)\n",
        "pandas_df['DeliveryStatus'] = pandas_df['DeliveryStatus'].replace(\"Cancelled\", \"Order Cancelled\")\n",
        "\n",
        "# ---- PySpark ----\n",
        "spark_df = spark_df.drop(\"CustomerSince\")\n",
        "spark_df = spark_df.withColumn(\"FinalAmount\", col(\"Amount\") - (col(\"Amount\") * col(\"Discount\")))\n",
        "spark_df = spark_df.orderBy(col(\"FinalAmount\").desc())\n",
        "spark_df = spark_df.withColumn(\"DeliveryStatus\", when(col(\"DeliveryStatus\") == \"Cancelled\", \"Order Cancelled\").otherwise(col(\"DeliveryStatus\")))\n",
        "\n",
        "# ---- Dask ----\n",
        "dask_df = dask_df.drop(\"CustomerSince\", axis=1)\n",
        "dask_df['FinalAmount'] = dask_df['Amount'] - (dask_df['Amount'] * dask_df['Discount'])\n",
        "dask_df = dask_df.sort_values(\"FinalAmount\", ascending=False)\n",
        "dask_df['DeliveryStatus'] = dask_df['DeliveryStatus'].replace(\"Cancelled\", \"Order Cancelled\")\n",
        "\n",
        "# =============================\n",
        "# TASK 4: Aggregations and GroupBy\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "print(pandas_df['DeliveryStatus'].value_counts())\n",
        "print(pandas_df.groupby('ProductCategory')['Amount'].mean())\n",
        "print(pandas_df.groupby('City')['Amount'].sum())\n",
        "\n",
        "# ---- PySpark ----\n",
        "spark_df.groupBy(\"DeliveryStatus\").count().show()\n",
        "spark_df.groupBy(\"ProductCategory\").avg(\"Amount\").show()\n",
        "spark_df.groupBy(\"City\").sum(\"Amount\").show()\n",
        "\n",
        "# ---- Dask ----\n",
        "print(dask_df['DeliveryStatus'].value_counts().compute())\n",
        "print(dask_df.groupby('ProductCategory')['Amount'].mean().compute())\n",
        "print(dask_df.groupby('City')['Amount'].sum().compute())\n",
        "\n",
        "# =============================\n",
        "# TASK 5: Null Handling & Update\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "pandas_df.loc[::50, 'City'] = None\n",
        "pandas_df.fillna({'City': 'Unknown'}, inplace=True)\n",
        "\n",
        "# ---- PySpark ----\n",
        "from pyspark.sql.functions import lit\n",
        "spark_df = spark_df.withColumn(\"City\", when((col(\"City\") == \"\") | col(\"City\").isNull(), lit(None)).otherwise(col(\"City\")))\n",
        "spark_df = spark_df.fillna({'City': 'Unknown'})\n",
        "spark_df = spark_df.withColumn(\"CustomerTag\", when(col(\"Amount\") > 800, \"High-Value\").otherwise(\"Regular\"))\n",
        "\n",
        "# ---- Dask ----\n",
        "dask_df.loc[::50, 'City'] = None\n",
        "dask_df = dask_df.fillna({'City': 'Unknown'})\n",
        "\n",
        "# =============================\n",
        "# TASK 6: Date & Time Functions\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "pandas_df['OrderDate'] = pd.to_datetime(pandas_df['OrderDate'])\n",
        "pandas_df['Year'] = pandas_df['OrderDate'].dt.year\n",
        "pandas_df['Month'] = pandas_df['OrderDate'].dt.month\n",
        "\n",
        "# ---- PySpark ----\n",
        "spark_df = spark_df.withColumn(\"OrderDate\", to_date(col(\"OrderDate\"), \"yyyy-MM-dd\"))\n",
        "spark_df = spark_df.withColumn(\"Year\", year(col(\"OrderDate\")))\n",
        "spark_df = spark_df.withColumn(\"Month\", month(col(\"OrderDate\")))\n",
        "\n",
        "# ---- Dask ----\n",
        "dask_df['OrderDate'] = dd.to_datetime(dask_df['OrderDate'])\n",
        "dask_df['Year'] = dask_df['OrderDate'].dt.year\n",
        "dask_df['Month'] = dask_df['OrderDate'].dt.month\n",
        "\n",
        "# =============================\n",
        "# TASK 7: Joins and Unions\n",
        "# =============================\n",
        "\n",
        "# ---- Setup a simple mapping DataFrame ----\n",
        "city_region_data = pd.DataFrame({\n",
        "    \"City\": pandas_df['City'].unique(),\n",
        "    \"Region\": [\"North\", \"South\", \"East\", \"West\"] * 20  # random repeating\n",
        "})\n",
        "region_df_spark = spark.createDataFrame(city_region_data)\n",
        "region_df_dask = dd.from_pandas(city_region_data, npartitions=1)\n",
        "\n",
        "# ---- Joins ----\n",
        "spark_df.join(region_df_spark, on=\"City\", how=\"inner\").show()\n",
        "spark_df.join(region_df_spark, on=\"City\", how=\"left\").show()\n",
        "\n",
        "# ---- Union ----\n",
        "df_2023 = spark_df.filter(year(\"OrderDate\") == 2023)\n",
        "df_2024 = spark_df.filter(year(\"OrderDate\") == 2024)\n",
        "df_union = df_2023.union(df_2024)\n",
        "df_union.show()\n",
        "\n",
        "# =============================\n",
        "# TASK 8: Complex JSON Simulation (Advanced)\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "json_series = pandas_df.apply(lambda row: row.to_json(), axis=1)\n",
        "json_df = pd.read_json(json_series.to_json(), typ='series')\n",
        "\n",
        "# ---- PySpark ----\n",
        "spark_df_json = spark_df.withColumn(\"json\", col(\"OrderID\").cast(StringType()))\n",
        "# Normally you'd use `to_json(struct(...))` and explode a nested array\n",
        "\n",
        "# =============================\n",
        "# TASK 9: Applying Functions\n",
        "# =============================\n",
        "\n",
        "# ---- Pandas ----\n",
        "def tag_order(amount):\n",
        "    if amount > 800:\n",
        "        return \"Big\"\n",
        "    elif amount > 400:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Small\"\n",
        "\n",
        "pandas_df['OrderTag'] = pandas_df['Amount'].apply(tag_order)\n",
        "\n",
        "# ---- PySpark ----\n",
        "@udf(returnType=StringType())\n",
        "def tag_udf(amount):\n",
        "    if amount > 800:\n",
        "        return \"Big\"\n",
        "    elif amount > 400:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Small\"\n",
        "\n",
        "spark_df = spark_df.withColumn(\"OrderTag\", tag_udf(col(\"Amount\")))\n",
        "\n",
        "# ---- Dask ----\n",
        "dask_df['OrderTag'] = dask_df['Amount'].map(tag_order)\n"
      ]
    }
  ]
}